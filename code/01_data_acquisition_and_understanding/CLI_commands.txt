Create dl4nlp-cluster.compute to point to an HDI cluster

az ml computetarget attach --name dl4nlp-cluster --address dl4nlp-cluster-ssh.azurehdinsight.net --username sshuser --password <password> --type cluster
az ml experiment prepare -c dl4nlp-cluster

Run te script in a remote HDInsight cluster:

az ml experiment submit -c dl4nlp-cluster 1_Download_and_Parse_XML_Spark.py

az ml experiment submit -c dl4nlp-cluster 2_Train_Word2Vec_Model_Spark.py


# Get rg from this command
az ml env list

# Create realtime service
az ml env setup -g env4entityextractorrg -n env4entityextractor --cluster -z 5 -l eastus2 -yes

# Set up AML environment and compute with ACS
az ml env set --cluster-name env4entityextractor --resource-group env4entityextractorrg

C:\dl4nlp\models>az ml service create realtime -n extract-biomedical-entities -f score.py -m lstm_bidirectional_model.h5 -s service-schema.json -r python -d w2vmodel_pubmed_vs_50_ws_5_mc_400.pkl -d tag_map.tsv -d DataReader.py -d EntityExtractor.py -c scoring_conda_dependencies.yml